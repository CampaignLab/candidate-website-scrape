---
title: "Candidate Website Data Coverage"
subtitle: "UK 2024 General Election"
date: today
format: 
  html:
    toc: true
    toc-location: left
    code-fold: true
    theme: cosmo
    embed-resources: true
    smooth-scroll: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(jsonlite)
library(here)
library(networkD3)
library(DT)

source(here("docs/scripts/load_websites.R"))
```

::: {.callout-note}
## About this data

This report shows coverage statistics for candidate website data scraped from the 2024 UK General Election. Candidate data was collected from [Democracy Club](https://candidates.democracyclub.org.uk/), a crowdsourced database of UK electoral candidates.

**Report last updated:** `r format(Sys.Date(), "%B %d, %Y")`
:::

```{r}
#| label: load-data

# Load all candidates from Democracy Club
all_candidates <- read.csv(here("assets/data/candidatesfull_25-12-12.csv"))
ge_all <- all_candidates[all_candidates$election_id == "parl.2024-07-04", ]

# Load scraped websites
ge_2024 <- load_candidate_websites(
    candidates_file = here("assets/data/candidates.csv"),
    json_dirs = c(here("assets/json"), here("assets/large_json")),
  election_filter = "parl.2024-07-04",
  keep_vars = c("person_id", "person_name", "party_name", "homepage_url", "elected")
)

# Merge to identify missing
ge_all <- merge(
  ge_all, 
  data.frame(person_id = ge_2024$person_id, has_scraped_data = TRUE),
  by = "person_id",
  all.x = TRUE
)
ge_all$has_scraped_data[is.na(ge_all$has_scraped_data)] <- FALSE
```

# Coverage Summary


```{r}
#| label: coverage-stats

# Total candidates in 2024 GE
n_total <- nrow(ge_all)

# Candidates with homepage URLs in Democracy Club
n_with_urls <- sum(!is.na(ge_all$homepage_url) & ge_all$homepage_url != "")

# Candidates with scraped data
n_scraped <- sum(ge_all$has_scraped_data)

# Coverage rates
url_coverage <- n_with_urls / n_total * 100
scrape_coverage <- n_scraped / n_total * 100
scrape_success <- n_scraped / n_with_urls * 100

coverage_summary <- data.frame(
  Metric = c("Total candidates", 
             "Candidates with homepage URLs", 
             "Candidates with scraped websites",
             "Scraping success rate"),
  Count = c(n_total, n_with_urls, n_scraped, NA),
  Percentage = c(NA, url_coverage, scrape_coverage, scrape_success)
)

knitr::kable(coverage_summary, 
             col.names = c("Metric", "N", "% of total"),
             digits = 1,
             format.args = list(big.mark = ","))
```

## Attrition Flow

```{r}
#| label: fig-sankey-attrition
#| fig-width: 12
#| fig-height: 8

# Calculate attrition numbers
n_no_url <- n_total - n_with_urls
n_scrape_fail <- n_with_urls - n_scraped

# Create nodes
nodes <- data.frame(
  name = c(
    "All candidates",
    "Has URL",
    "No URL",
    "Successfully scraped",
    "Scraping failed"
  )
)

# Create links
links <- data.frame(
  source = c(0, 0, 1, 1),
  target = c(1, 2, 3, 4),
  value = c(n_with_urls, n_no_url, n_scraped, n_scrape_fail)
)

# Create color scale (neutral grays)
color_scale <- 'd3.scaleOrdinal()
  .range(["#808080", "#999999", "#b3b3b3", "#cccccc", "#666666"])'

# Create Sankey
sankeyNetwork(
  Links = links,
  Nodes = nodes,
  Source = "source",
  Target = "target",
  Value = "value",
  NodeID = "name",
  units = "candidates",
  fontSize = 13,
  nodeWidth = 35,
  colourScale = color_scale
)
```

# Coverage by Party

```{r}
#| label: party-groups

ge_all$party_group <- ifelse(ge_all$party_name == "Labour Party", "LAB",
                       ifelse(ge_all$party_name == "Labour and Co-operative Party", "LAB",
                       ifelse(ge_all$party_name == "Conservative and Unionist Party", "CON",
                       ifelse(ge_all$party_name == "Liberal Democrats", "LDM",
                       ifelse(ge_all$party_name == "Reform UK", "REF",
                       ifelse(ge_all$party_name == "Green Party", "GRN",
                       ifelse(ge_all$party_name == "Scottish National Party (SNP)", "SNP",
                       ifelse(ge_all$party_name == "Plaid Cymru - The Party of Wales", "PLD",
                       ifelse(ge_all$party_name == "Democratic Unionist Party - D.U.P.", "DUP",
                       ifelse(ge_all$party_name == "Sinn Féin", "SF",
                       "Other"))))))))))

ge_2024$party_group <- ifelse(ge_2024$party_name == "Labour Party", "LAB",
                       ifelse(ge_2024$party_name == "Labour and Co-operative Party", "LAB",
                       ifelse(ge_2024$party_name == "Conservative and Unionist Party", "CON",
                       ifelse(ge_2024$party_name == "Liberal Democrats", "LDM",
                       ifelse(ge_2024$party_name == "Reform UK", "REF",
                       ifelse(ge_2024$party_name == "Green Party", "GRN",
                       ifelse(ge_2024$party_name == "Scottish National Party (SNP)", "SNP",
                       ifelse(ge_2024$party_name == "Plaid Cymru - The Party of Wales", "PLD",
                       ifelse(ge_2024$party_name == "Democratic Unionist Party - D.U.P.", "DUP",
                       ifelse(ge_2024$party_name == "Sinn Féin", "SF",
                       "Other"))))))))))

coverage_by_party <- aggregate(
  list(
    total = rep(1, nrow(ge_all)),
    has_url = (!is.na(ge_all$homepage_url) & ge_all$homepage_url != "") * 1,
    has_scraped = ge_all$has_scraped_data * 1
  ),
  by = list(party_group = ge_all$party_group),
  FUN = sum
)

coverage_by_party$url_pct <- coverage_by_party$has_url / coverage_by_party$total * 100
coverage_by_party$scraped_pct <- coverage_by_party$has_scraped / coverage_by_party$total * 100
coverage_by_party$success_rate <- coverage_by_party$has_scraped / coverage_by_party$has_url * 100

coverage_by_party <- coverage_by_party[order(-coverage_by_party$total), ]
```


```{r}
#| label: fig-coverage-by-party
#| fig-width: 12
#| fig-height: 7

# Define party colors
party_colors <- c(
  "LAB" = "#E4003B",
  "CON" = "#0087DC", 
  "LDM" = "#FAA61A",
  "REF" = "#12B6CF",
  "GRN" = "#6AB023",
  "SNP" = "#FDF38E",
  "PLD" = "#008142",
  "DUP" = "#D46A4C",
  "SF" = "#326760"
)

# Filter out "Other"
coverage_filtered <- coverage_by_party[coverage_by_party$party_group != "Other", ]

# Create ordering based on total candidates
total_order <- coverage_filtered$party_group[order(-coverage_filtered$total)]

# Create stacked data
coverage_long <- data.frame(
  party_group = rep(coverage_filtered$party_group, 3),
  type = rep(c("Successfully scraped", "URL not scraped", "No URL"), each = nrow(coverage_filtered)),
  count = c(
    coverage_filtered$has_scraped,
    coverage_filtered$has_url - coverage_filtered$has_scraped,
    coverage_filtered$total - coverage_filtered$has_url
  )
)

coverage_long$party_group <- factor(coverage_long$party_group, levels = total_order)

coverage_long$type <- factor(coverage_long$type, 
                              levels = c("Successfully scraped", "URL not scraped", "No URL"))

coverage_long$alpha <- ifelse(coverage_long$type == "Successfully scraped", 1,
                       ifelse(coverage_long$type == "URL not scraped", 0.6, 0.3))

ggplot(coverage_long, aes(x = party_group, y = count, 
                          fill = party_group, alpha = alpha)) +
  geom_col(position = "stack") +
  geom_text(aes(label = count), 
            position = position_stack(vjust = 0.5),
            color = "black", size = 3.5) +
  scale_fill_manual(values = party_colors) +
  scale_alpha_identity() +
  labs(
    title = "Candidate website coverage by party",
    subtitle = "Darkest = successfully scraped | Medium = URL not scraped | Lightest = no URL",
    x = NULL,
    y = "Number of candidates",
    fill = "Party"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold", size = 16)
  )
```

```{r}
#| label: coverage-by-party-print

coverage_by_party_display <- coverage_by_party[coverage_by_party$party_group != "Other", ]
coverage_by_party_other <- coverage_by_party[coverage_by_party$party_group == "Other", ]
coverage_by_party_display <- rbind(coverage_by_party_display, coverage_by_party_other)

datatable(coverage_by_party_display, 
          colnames = c("Party", "N Candidates", "N URLs", "N scraped", 
                       "% Candidates with URL", "% Candidates scraped", "% URLs scraped"),
          rownames = FALSE,
          options = list(
            pageLength = nrow(coverage_by_party_display),
            dom = 't',
            order = list(list(1, 'desc'))
          ),
          class = 'cell-border stripe') %>%
  formatRound(columns = c(5, 6, 7), digits = 1)
```


## Party-level attrition flow

```{r}
#| label: fig-sankey-major-parties-colored
#| fig-width: 15
#| fig-height: 20

# Filter to major parties
major_parties <- c("LAB", "CON", "LDM", "REF", "GRN")
party_attrition <- coverage_by_party[coverage_by_party$party_group %in% major_parties, ]

# Create nodes
nodes <- data.frame(
  name = c(
    "All candidates",
    party_attrition$party_group,
    paste(party_attrition$party_group, "Has URL"),
    paste(party_attrition$party_group, "No URL"),
    paste(party_attrition$party_group, "Scraped"),
    paste(party_attrition$party_group, "Failed")
  )
)

# Add party colors to nodes
party_colors <- c(
  "LAB" = "#E4003B",
  "CON" = "#0087DC", 
  "LDM" = "#FAA61A",
  "REF" = "#12B6CF",
  "GRN" = "#6AB023"
)

nodes$group <- c(
  "All",
  party_attrition$party_group,
  party_attrition$party_group,
  party_attrition$party_group,
  party_attrition$party_group,
  party_attrition$party_group
)

# Create links
n_parties <- nrow(party_attrition)

links <- data.frame(
  source = c(
    rep(0, n_parties),
    1:(n_parties),
    1:(n_parties),
    6:(6+n_parties-1),
    6:(6+n_parties-1)
  ),
  target = c(
    1:(n_parties),
    6:(6+n_parties-1),
    11:(11+n_parties-1),
    16:(16+n_parties-1),
    21:(21+n_parties-1)
  ),
  value = c(
    party_attrition$total,
    party_attrition$has_url,
    party_attrition$total - party_attrition$has_url,
    party_attrition$has_scraped,
    party_attrition$has_url - party_attrition$has_scraped
  )
)

links <- links[links$value > 0, ]

color_scale <- paste0('d3.scaleOrdinal()
  .domain(["All", "LAB", "CON", "LDM", "REF", "GRN"])
  .range(["#999999", "', party_colors["LAB"], '", "', 
         party_colors["CON"], '", "', party_colors["LDM"], '", "', 
         party_colors["REF"], '", "', party_colors["GRN"], '"])')

sankeyNetwork(
  Links = links,
  Nodes = nodes,
  Source = "source",
  Target = "target",
  Value = "value",
  NodeID = "name",
  NodeGroup = "group",
  units = "candidates",
  fontSize = 11,
  nodeWidth = 25,
  nodePadding = 10,
  colourScale = color_scale
)
```


